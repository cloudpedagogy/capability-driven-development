# Purpose and Scope

_Status: Draft_

---

## Purpose of Capability-Driven Development

Capability-Driven Development (CDD) exists to address a persistent gap in the design of AI-enabled software systems.

While many organisations now recognise the importance of ethical, responsible, and human-centred AI, these concerns are often addressed:
- after systems are built
- through policy rather than design
- as compliance checks rather than structural constraints

CDD provides a **practical design approach** for ensuring that human, organisational, and institutional capability requirements are embedded **before** automation, architecture, or implementation decisions are made.

Its purpose is to support the design of systems that:
- preserve human judgement and responsibility
- remain governable and contestable
- can be explained, reviewed, and defended over time
- adapt without eroding institutional values

CDD is explicitly concerned with *how systems are designed*, not just how they are justified.

---

## What CDD Is For

Capability-Driven Development is intended to be used when designing or evolving **AI-enabled, socio-technical systems** where:

- AI influences decisions, workflows, or oversight
- human judgement remains ethically or institutionally necessary
- outcomes may be contested, reviewed, or appealed
- responsibility must remain attributable to people or roles
- systems operate in complex, changing contexts

Typical application areas include:
- education and curriculum-related systems
- research support and governance systems
- public-interest and public-service applications
- professional and institutional decision support
- workflow orchestration and monitoring systems

CDD is most valuable where **defensibility matters**.

---

## Scope of Application

CDD applies across the **system lifecycle**, including:

- early concept and design
- boundary-setting between humans and AI
- architectural and workflow design
- evaluation, monitoring, and iteration
- retirement, replacement, or deprecation

It is not limited to:
- a single project phase
- a specific organisational role
- a particular technology stack

CDD can be applied to:
- new system development
- redesign or refactoring of existing systems
- evaluation of proposed AI use cases
- critical review of deployed systems

---

## What CDD Does Not Attempt to Do

CDD does **not** aim to:

- prescribe specific tools, platforms, or models
- replace engineering or software development practices
- automate ethical decision-making
- serve as a compliance or certification framework
- provide policy or legal advice

Instead, CDD focuses on **design intent, structure, and responsibility**, leaving implementation choices to be made within those constraints.

---

## Relationship to Practice

CDD is designed to be:
- usable by designers, developers, and applied researchers
- compatible with existing development methodologies
- adaptable to local context and institutional requirements

It is not a standalone solution.

CDD works best when used alongside:
- the CloudPedagogy AI Capability Framework
- professional judgement and domain expertise
- institutional governance and policy processes

CDD supports practice by making capability requirements explicit and operational.

---

## Summary

Capability-Driven Development exists to ensure that AI-enabled systems are designed in ways that:

- strengthen, rather than substitute for, human capability
- make responsibility visible and defensible
- embed governance into system structure
- remain adaptable without losing legitimacy

Its scope is deliberately focused:  
CDD is about **how we design systems that must remain responsible**, even as technologies change.
