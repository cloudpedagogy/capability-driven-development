# Governance and Oversight Plan

_Status: Draft_

---

## Purpose of This Plan

This document describes **how responsibility, oversight, and accountability are exercised in practice** for an AI-enabled system.

It exists to ensure that:
- responsibility is clearly assigned to human roles
- oversight is active rather than symbolic
- escalation, review, and contestation are possible in practice
- the system remains governable over time

This is a **design artefact**, not a policy document or compliance checklist.

---

## System Context

**System name:**  
*(As per the System Capability Brief)*

**Context of use:**  
*(Education, research, public service, professional practice, etc.)*

**Primary capability intent:**  
*(Restated briefly from the Capability Brief)*

---

## Governance Objectives

What does governance need to achieve for this system?

Examples:
- preserve human judgement and accountability
- ensure ethical and equitable use
- enable review and correction of system behaviour
- maintain institutional defensibility
- support learning and adaptation

Governance objectives should reflect **capability**, not just risk control.

---

## Accountable Roles and Responsibilities

### Primary Accountable Roles

List the roles that remain accountable for outcomes influenced by the system.

For each role, clarify:
- area of responsibility
- decision authority
- escalation or override powers

Example format:

- **Role:**  
  **Responsibilities:**  
  **Authority:**  

---

### Oversight and Review Roles

Identify roles or groups responsible for **ongoing oversight**, such as:
- review panels
- governance committees
- quality assurance leads
- ethics or risk bodies

Clarify how oversight differs from day-to-day use.

---

## Oversight Activities

Describe how the system is **actively overseen**.

Consider:
- what is reviewed
- how often
- by whom
- using what evidence

Examples:
- periodic review of system use patterns
- examination of escalation or override cases
- review of equity impacts
- assessment of alignment with capability intent

Oversight should be *proportionate* and *purposeful*.

---

## Escalation and Exception Handling

Describe how concerns, uncertainty, or incidents are escalated.

Questions to address:
- What triggers escalation?
- Who can escalate?
- Who receives escalated issues?
- How quickly must escalation be addressed?

Escalation should be accessible and non-punitive.

---

## Contestation and Challenge

Describe how system behaviour or outcomes can be challenged.

Consider:
- who may raise challenges
- what forms challenge may take
- how challenges are reviewed
- how outcomes are recorded

Challenge is a **governance signal**, not a failure.

---

## Transparency and Record-Keeping

What records are kept to support governance?

Consider:
- decisions and outcomes
- overrides and escalations
- reviews and findings
- changes to scope or behaviour

Records should support **understanding and accountability**, not surveillance.

---

## Change Control and Scope Management

Describe how changes to the system are governed.

Consider:
- who can approve changes
- how boundary changes are reviewed
- how ethical or equity impacts are reassessed
- how users are informed

Changes should not bypass governance.

---

## Relationship to Other Design Artifacts

This plan:
- operationalises the **System Capability Brief**
- depends on the **Humanâ€“AI Boundary Map**
- responds to the **Ethics, Equity, and Risk Notes**
- informs the **Evaluation and Learning Log**
- supports decisions recorded in **Retirement and Transition Notes**

Governance should be consistent across all artefacts.

---

## Review and Update

**Date created:**  
**Created by:**  

**Last reviewed:**  
**Review notes:**  

Governance arrangements should be reviewed:
- periodically
- after incidents or challenges
- when system scope changes

---

## Summary

This Governance and Oversight Plan exists to answer one question clearly:

> **How is responsibility for this system exercised, reviewed, and defended in practice?**

If that answer becomes unclear, the system is no longer governable.
