# System Capability Brief

_Status: Draft_

---

## Purpose of This Brief

This document captures the **capability intent** of an AI-enabled system **before** technical design, automation, or implementation decisions are made.

It exists to ensure that:
- the system’s purpose is explicit
- critical human and institutional capabilities are identified
- responsibility is preserved by design
- later design decisions remain defensible

This brief should be completed **early** and revisited as the system evolves.

It is not a specification or approval document.  
It is a **thinking and alignment tool**.

---

## System Overview

**Working system name:**  
*(Descriptive, provisional)*

**Context of use:**  
*(e.g. education, research, public service, professional practice)*

**Problem or need being addressed:**  
*(Describe the situation this system responds to, not the solution)*

---

## Capability Intent

### Primary Capability Intent

What **human or institutional capability** must this system support or strengthen?

Examples:
- professional judgement
- coordinated decision-making
- oversight and accountability
- equitable access to support
- transparency and defensibility

Describe this in plain language.

---

### Capabilities That Must Be Preserved

Which capabilities **must not be displaced or weakened** by the system?

Consider:
- decision authority
- ethical reasoning
- contextual interpretation
- accountability and ownership
- care, discretion, or professional responsibility

If these capabilities were lost, what would be at risk?

---

### Capabilities the System May Support (But Not Replace)

Which activities could be **assisted** by automation without transferring responsibility?

Examples:
- summarisation
- pattern surfacing
- coordination
- reminder or signal generation

Be explicit about *support*, not substitution.

---

## Non-Goals and Explicit Limits

What is this system **not intended** to do?

Examples:
- make final decisions
- enforce compliance
- replace professional roles
- optimise for speed at the expense of judgement
- operate without human oversight

Explicit non-goals protect against scope creep.

---

## Stakeholders and Responsibility

### Primary Human Roles

Who remains **responsible** for outcomes influenced by this system?

List roles, not individuals.

Examples:
- programme leads
- reviewers
- advisors
- managers
- governance bodies

---

### Affected Parties

Who may be affected by system outputs or behaviour?

Consider:
- direct users
- indirect subjects
- groups potentially disadvantaged or excluded

This informs later ethical and equity considerations.

---

## Why an AI-Enabled System Is Being Considered

Why is AI being explored **in this context**?

Examples:
- scale of information
- coordination complexity
- timeliness
- consistency support

What would **not** justify AI use here?

This section helps resist technology-first design.

---

## Risks of Capability Erosion

What could go wrong if this system is poorly designed?

Consider risks such as:
- over-reliance on automation
- loss of judgement
- accountability gaps
- inequitable outcomes
- reduced contestability

These risks should be revisited in later artifacts.

---

## Success Criteria (Capability-Focused)

How will you know if the system is **supporting capability**, not undermining it?

Focus on qualitative signals, for example:
- users report increased clarity, not loss of agency
- decisions remain explainable
- escalation and challenge still occur
- governance processes remain effective

Avoid purely technical performance metrics here.

---

## Relationship to Other Design Artifacts

This brief informs and constrains:
- the **Human–AI Boundary Map**
- **Ethics, Equity, and Risk Notes**
- **Governance and Oversight Plan**
- **System Design Decisions**
- **Evaluation and Learning Log**

If later artifacts contradict this brief, the contradiction should be explicit and justified.

---

## Review and Revision

**Date created:**  
**Created by:**  

**Last reviewed:**  
**Review notes:**  

This brief is expected to evolve.  
Changes should reflect learning, not convenience.

---

## Summary

This System Capability Brief exists to make one thing clear:

> **What capability must this system protect, and why does that matter?**

Everything that follows in the design process should be traceable back to this intent.
